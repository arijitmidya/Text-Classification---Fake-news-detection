{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b671f7dc-2819-4adb-9915-dea2c275ba8e",
   "metadata": {},
   "source": [
    "# Fake News Detection Using Scikit-learn\n",
    "\n",
    "Let’s start this project with a simple question, do you trust all the news from social media? How can we detect fake news from real news? It’s a \n",
    "tough question. Luckily, we can detect fake news using a supervised machine learning method.\n",
    "\n",
    "Fake news is a piece of news that is not true and deliberately designed to mislead people. It is usually spread via social media or other online\n",
    "platforms. Fake news is usually politically driven to give advantages or disadvantages to a political party. Such news items may contain false and\n",
    "exaggerated claims and because of certain algorithms, trap users in a filter bubble.\n",
    "\n",
    "In this project, we’ll use two different datasets:\n",
    "\n",
    "News dataset available on Kaggle.\n",
    "    \n",
    "The second dataset we’ll create ourselves using the News API. We will use this API to load some data and then append that data to the other dataset.\n",
    "    \n",
    "In the end, we will use a passive-aggressive classifier to classify and differentiate the fake news from the real ones. The\n",
    "passive-aggressive classifier is a classification algorithm in machine learning that changes the model whenever there is a wrong prediction. \n",
    "If there is no wrong prediction, the model will stay the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d9f4b8-a1ef-4cc9-a9e0-8dcc6d688159",
   "metadata": {},
   "source": [
    "# Task 1 : Import Modules\n",
    "\n",
    "Let’s start the project by importing the necessary modules. To start with the News API, import the following modules:\n",
    "\n",
    "NewsApiClient from newsapi: This module will be used to interact with the API and get the news from different sources.\n",
    "\n",
    "random: This module will be used to generate random numbers for the news.\n",
    "                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "929dca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Import Modules\n",
    "\n",
    "from newsapi import NewsApiClient\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cfe7cc-dacd-4e70-a8f3-9bfaa44746b6",
   "metadata": {},
   "source": [
    "# Task 2: Create a Get News Method\n",
    "\n",
    "In this task, create a method to get the news data from the News API. To interact with the News API, an API key is required.\n",
    "\n",
    "After we get your API key, do the following steps:\n",
    "\n",
    "1. Call the NewsApiClient() method and pass the API key to this method.\n",
    "\n",
    "2. Create a method to get the news data from the API.\n",
    "\n",
    "3. Use the get_everything() method from the NewsApiClient to get data and pass the following parameters to the method:\n",
    "\n",
    "sources: This is used to specify the source to get news from. This is a comma-separated string.\n",
    "\n",
    "domains: This is used to restrict the domain of search. This is a comma-separated string.\n",
    "\n",
    "from_param: This specifies the oldest news to get from the API.\n",
    "\n",
    "to: To specify the date of the newest news from the search.\n",
    "\n",
    "language: This is used to specify the language of response from the API. Possible values for these parameters are \n",
    "ar, de, en, es, fr, he, it, nl, no, pt, ru, sv, ud, zh. By default, it will use all the available languages.\n",
    "\n",
    "sort_by: This is used to specify the order of the news to get from the search. Some possible options are relevancy, popularity, publishedAt.\n",
    "By default, the method will sort the records by their publishing date.\n",
    "\n",
    "page: This is used to specify the page of the source to get the results from. By default this will use the first page to get the results.\n",
    "\n",
    "4. After getting the results from the API, pass the results to an array and return that array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7685e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Create a Get News Method\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "prev_date = datetime.today() - timedelta(days=30)\n",
    "next_date = datetime.today() - timedelta(days=0)\n",
    "p_date = str(prev_date.year)+'-'+str(prev_date.month)+'-'+str(prev_date.day)\n",
    "c_date = str(next_date.year)+'-'+str(next_date.month)+'-'+str(next_date.day)\n",
    "if prev_date.month < 10:\n",
    "    p_date = str(prev_date.year)+'-0'+str(prev_date.month)+'-'+str(prev_date.day)\n",
    "else:\n",
    "    p_date = str(prev_date.year)+'-'+str(prev_date.month)+'-'+str(prev_date.day)\n",
    "\n",
    "if next_date.month < 10:\n",
    "    c_date = str(next_date.year)+'-0'+str(next_date.month)+'-'+str(next_date.day)\n",
    "else:\n",
    "    c_date = str(next_date.year)+'-'+str(next_date.month)+'-'+str(next_date.day)\n",
    "\n",
    "# Task 2: Create a Get News Method\n",
    "newsapi = NewsApiClient(api_key='204af192d1f549d794e8bf6ddb9da66a')\n",
    "def getNews(sourceId):\n",
    "    newses = newsapi.get_everything(sources=sourceId,domains='bbc.co.uk,techcrunch.com',from_param=p_date,to=c_date,language='en',sort_by='relevancy',page=2)\n",
    "    newsData = []\n",
    "    for news in newses['articles']:\n",
    "        list = [random.randint(0, 1000), news['title'],news['content'], 'REAL']\n",
    "        newsData.append(list)\n",
    "    return newsData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bf5ef4-9ff7-452c-9a56-f27194c586f9",
   "metadata": {},
   "source": [
    "# Task 3: Get News Sources\n",
    "\n",
    "The official documentation of the News API says that there are 3000 authenticated news sources.\n",
    "\n",
    "In this task, let’s get the news sources using the News API. Do the following:\n",
    "\n",
    "1. Get all the sources from the News API.\n",
    "\n",
    "2. Add the ID of each source to a list.\n",
    "    \n",
    "3. Truncate the list to a size of 10, and get news from those sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f557dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Sources:  ['abc-news', 'abc-news-au', 'aftenposten', 'al-jazeera-english', 'ansa', 'argaam', 'ars-technica', 'ary-news', 'associated-press', 'australian-financial-review']\n"
     ]
    }
   ],
   "source": [
    "# Task 3: Get News Sources\n",
    "\n",
    "sources = newsapi.get_sources()\n",
    "sourceList = []\n",
    "for source in sources['sources']:\n",
    "    sourceList.append(source['id'])\n",
    "del sourceList[10:len(sourceList)]\n",
    "print('New Sources: ', sourceList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d204895d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc-news',\n",
       " 'abc-news-au',\n",
       " 'aftenposten',\n",
       " 'al-jazeera-english',\n",
       " 'ansa',\n",
       " 'argaam',\n",
       " 'ars-technica',\n",
       " 'ary-news',\n",
       " 'associated-press',\n",
       " 'australian-financial-review']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourceList."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877c4422-b784-4128-8a14-4c79ce386c84",
   "metadata": {},
   "source": [
    "# Task 4: Get News using Multiple Sources\n",
    "\n",
    "After getting the news sources, complete the following steps to get the news from the API:\n",
    "\n",
    "1. Use the getNews() method from Task 2 to get the news from the API.\n",
    "\n",
    "2. Use a loop to pass all sources to the method.\n",
    "    \n",
    "3. Add all the returned news to a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b02ab672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total News:  1000\n"
     ]
    }
   ],
   "source": [
    "# Task 4: Get News using Multiple Sources\n",
    "\n",
    "dataList = []\n",
    "for sourceId in sourceList:\n",
    "    newses = getNews(sourceId)\n",
    "    dataList = dataList + newses\n",
    "\n",
    "print('Total News: ', len(dataList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31102f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[806, 'Federal prosecutors charge Ryan Routh with attempted assassination of Donald Trump', 'Federal prosecutors have officially charged Ryan Routh with attempting to assassinate former President Donald Trump, a source familiar with the matter confirmed to ABC News.\\r\\nThe move was expected an… [+591 chars]', 'REAL']\n",
      "====================================================================================================\n",
      "[979, 'In the Studio: Lenin Tamayo and Q-pop', 'Peruvian singer Lenin Tamayo has been dubbed the founder of Q-pop. He combines traditional Andean folk music with K-pop inspired instrumentation and dance. His songs mix Quechua one of Perus indigeno… [+643 chars]', 'REAL']\n",
      "====================================================================================================\n",
      "[131, '21/09/2024 04:01 GMT', 'The latest five minute news bulletin from BBC World Service.', 'REAL']\n"
     ]
    }
   ],
   "source": [
    "print(dataList[1])\n",
    "print('='*100)\n",
    "print(dataList[500])\n",
    "print('='*100)\n",
    "print(dataList[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ddebe-7bdf-4c6f-a997-cc854cb03f6a",
   "metadata": {},
   "source": [
    "# Task 5: Create a DataFrame of News\n",
    "\n",
    "In this task, create a new DataFrame using the news list. To complete the task, do the following:\n",
    "\n",
    "1. Use the from_records() method from pandas.DataFrame to create a new DataFrame using the list.\n",
    "    \n",
    "2. Add new column headings to the DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "473d30d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    title  \\\n",
      "0  842  2024 election updates: Nebraska governor ends ...   \n",
      "1  806  Federal prosecutors charge Ryan Routh with att...   \n",
      "2  102  Trump claims women won't 'be thinking about ab...   \n",
      "3  562  Missouri executes a man for the 1998 killing o...   \n",
      "4  897  Death row inmate Marcellus Williams executed b...   \n",
      "\n",
      "                                                text label  \n",
      "0  Trump is expected to return to Butler, Pennsyl...  REAL  \n",
      "1  Federal prosecutors have officially charged Ry...  REAL  \n",
      "2  Former President Donald Trump appears to be tr...  REAL  \n",
      "3  Missouri executes a man for the 1998 killing o...  REAL  \n",
      "4  Missouri death row inmate Marcellus Williams w...  REAL  \n"
     ]
    }
   ],
   "source": [
    "# Task 5: Create a DataFrame of News\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_records(dataList)\n",
    "df.columns = ['','title','text','label']\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2b4597-a633-4604-8660-3c2f378ed099",
   "metadata": {},
   "source": [
    "# Task 6: Load and Concat the DataFrame\n",
    "\n",
    "As News API claims that all of their news are authenticated, you need another dataset that contains both fake news and real news to train the model. \n",
    "To create a DataFrame that consists of fake news and real news, complete the following steps:\n",
    "\n",
    "1. Load the data from a .csv file available in the same directory with the name of the news.csv file.\n",
    "\n",
    "2. Add the column headings to the DataFrame.\n",
    "\n",
    "3. Use pandas to concat both DataFrames to create a new DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "475093db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      title  \\\n",
      "0   8476                       You Can Smell Hillary’s Fear   \n",
      "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
      "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
      "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
      "4    875   The Battle of New York: Why This Primary Matters   \n",
      "\n",
      "                                                text label  \n",
      "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
      "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
      "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
      "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
      "4  It's primary day in New York and front-runners...  REAL  \n"
     ]
    }
   ],
   "source": [
    "# Task 6: Load and Concat the DataFrame\n",
    "\n",
    "trainData = pd.read_csv('news.csv')\n",
    "trainData.columns = ['', 'title', 'text', 'label']\n",
    "data = [trainData, df]\n",
    "df = pd.concat(data)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8420c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    4171\n",
       "FAKE    3164\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a076891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      title  \\\n",
       "0   8476                       You Can Smell Hillary’s Fear   \n",
       "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4    875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2874cad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7335, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3348f33c-5f64-45ac-89f0-330846627f15",
   "metadata": {},
   "source": [
    "# Task 7: Import Scikit Modules \n",
    "\n",
    "Let’s start creating a training model over the DataFrame. To create the training model, you need to import the following modules:\n",
    "\n",
    "1. train_test_split from sklearn.model_selection: To create random training and testing subsets using the DataFrame.\n",
    "\n",
    "2. CountVectorizer from sklearn.feature_extraction.text: To create a matrix of token count from the text document.\n",
    "\n",
    "3. PassiveAggressiveClassifier from sklearn.linear_model: To create a linear model that will be used to classify the real news from fake news.\n",
    "\n",
    "4. accuracy_score from sklearn.metrics: To calculate the model’s accuracy by testing the model using the test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79ad5b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7: Import Scikit Modules\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cea3d2-d5bb-4b59-9b52-3cdb5b137e78",
   "metadata": {},
   "source": [
    "# Task 8: Split the Training and Testing Data\n",
    "\n",
    "In this task, split the training and testing data from the DataFrame. For this project, use 70% of the data for training and 30% for testing. \n",
    "To split the training and testing data, use the train_test_split() method. This method accepts the following parameters:\n",
    "\n",
    "*arrays: This parameter accepts lists, NumPy arrays, and pandas DataFrames. Pass the combination of title, text, and news labels to this parameter.\n",
    "\n",
    "test_size: This parameter accepts a floating value between 0.0 and 1.0 used to evaluate the percentage of testing data from the DataFrame.\n",
    "\n",
    "random_state: This parameter accepts an integer value used to add a random shuffle to the DataFrame before applying the split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9646b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 8: Split the Training and Testing Data\n",
    "\n",
    "training_x, testing_x, training_y, testing_y = train_test_split(\n",
    "    df['text'], df.label, test_size=0.3, random_state=7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c1923-bb92-44de-a423-69a5d42c2ef9",
   "metadata": {},
   "source": [
    "# Task 9: Feature Selection\n",
    "\n",
    "After splitting the training and testing data, let’s start the feature selection using the scikit-learn method CountVectorizer(). This method \n",
    "accepts the following parameters:\n",
    "\n",
    "1. stop_words: Stop words such as “and,” “the,” and “him” are assumed to be uninformative in representing the content of a text. Therefore they can be \n",
    "removed to avoid being interpreted as a signal for prediction. Similar words can be helpful for prediction in some cases, such as classifying \n",
    "writing style or personality.\n",
    "\n",
    "2. max_df: When creating the vocabulary, exclude terms with a document frequency that is strictly greater than the given threshold \n",
    "(corpus-specific stop words). If the parameter is a float, it represents a percentage of documents; otherwise, it means absolute counts.\n",
    "If the vocabulary is None, this parameter is ignored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fddec84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 9: Feature Selection\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english', max_df=0.7)\n",
    "feature_train = count_vectorizer.fit_transform(training_x)\n",
    "feature_test = count_vectorizer.transform(testing_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8afc4d-6de4-466b-8f80-f28e5eeb95bf",
   "metadata": {},
   "source": [
    "# Task 10: Initialise and Apply the Classifier\n",
    "\n",
    "After the feature selection, let’s apply the classifier to the training data. To apply the classifier to the data, use the following steps:\n",
    "\n",
    "1. Initialize the PassiveAggressiveClassifier. This is an algorithm from the online learning family of machine learning. This algorithm uses the\n",
    "passive technique, which states that if the prediction is correct, keep the model; only change the model if the prediction is incorrect. \n",
    "This method accepts the following parameters:\n",
    "\n",
    "max_iter: This defines the number of iterations to apply to the training data. With each iteration, it checks the prediction and updates itself.\n",
    "    \n",
    "2. Call the fit() method from the PassiveAggressiveClassifier and pass the features of the training data along with the labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01928cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PassiveAggressiveClassifier(max_iter=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PassiveAggressiveClassifier</label><div class=\"sk-toggleable__content\"><pre>PassiveAggressiveClassifier(max_iter=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PassiveAggressiveClassifier(max_iter=50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 10: Initialise and Apply the Classifier\n",
    "\n",
    "classifier = PassiveAggressiveClassifier(max_iter=50)\n",
    "classifier.fit(feature_train, training_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f6737-17ac-4853-8908-62bb5af98e7f",
   "metadata": {},
   "source": [
    "# Task 11: Test the classifier\n",
    "\n",
    "After classifying the data, let’s use the classifier to predict the results on the testing data. The testing data is the remaining 30% of the\n",
    "complete DataFrame we made earlier. To use the classifier, do the following:\n",
    "\n",
    "1. Use the predict() method from the classifier and pass the testing feature of the dataset.\n",
    "\n",
    "2. Use the accuracy_score() method to get the model’s score. This method accepts the following parameters:\n",
    "\n",
    "y_true: The accurate labels or output of the testing date.\n",
    "    \n",
    "y_pred: The results from the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f99fca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  91.09495683780099\n"
     ]
    }
   ],
   "source": [
    "# Task 11: Test the classifier\n",
    "\n",
    "prediction = classifier.predict(feature_test)\n",
    "score = accuracy_score(testing_y, prediction)\n",
    "\n",
    "print(\"Accuracy: \", score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1b4a3-2823-4b72-b758-f8d942e81ffc",
   "metadata": {},
   "source": [
    "# Task 12: Load the Test Data\n",
    "\n",
    "After completing the model, try it on test data which is not from any actual source but specifically created to verify the model. This DataFrame \n",
    "contains some fake news and some real news to verify the model. To create a DataFrame that consists of fake and real news,\n",
    "complete the following steps:\n",
    "\n",
    "1. Load the data from the test_data.csv file available in the same directory.\n",
    "    \n",
    "2. Print the head of the DataFrame to see the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a2dec36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>914</td>\n",
       "      <td>7014</td>\n",
       "      <td>Trumps Hollywood Walk of Fame star Destroyed w...</td>\n",
       "      <td>Trump's Hollywood Walk of Fame star Destroyed ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4058</td>\n",
       "      <td>6440</td>\n",
       "      <td>Corporate Army smashes Dakota barbarians near ...</td>\n",
       "      <td>Corporate Army smashes Dakota barbarians near ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4982</td>\n",
       "      <td>6125</td>\n",
       "      <td>German Panzers to Rumble Once More Along Russi...</td>\n",
       "      <td>Citizen journalism with a punch German Panzers...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>800</td>\n",
       "      <td>8389</td>\n",
       "      <td>Contaminated Food from China Now Entering the ...</td>\n",
       "      <td>Contaminated Food from China Now Entering the ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4871</td>\n",
       "      <td>976</td>\n",
       "      <td>Cruz likely to block Trump on a second ballot ...</td>\n",
       "      <td>Republican presidential candidate Ted Cruz is ...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 1                                              title  \\\n",
       "0         914        7014  Trumps Hollywood Walk of Fame star Destroyed w...   \n",
       "1        4058        6440  Corporate Army smashes Dakota barbarians near ...   \n",
       "2        4982        6125  German Panzers to Rumble Once More Along Russi...   \n",
       "3         800        8389  Contaminated Food from China Now Entering the ...   \n",
       "4        4871         976  Cruz likely to block Trump on a second ballot ...   \n",
       "\n",
       "                                                text label  \n",
       "0  Trump's Hollywood Walk of Fame star Destroyed ...  FAKE  \n",
       "1  Corporate Army smashes Dakota barbarians near ...  FAKE  \n",
       "2  Citizen journalism with a punch German Panzers...  FAKE  \n",
       "3  Contaminated Food from China Now Entering the ...  FAKE  \n",
       "4  Republican presidential candidate Ted Cruz is ...  REAL  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 12: Load the Test Data\n",
    "\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "test_labels = test_data.label\n",
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf87481-720a-403b-9b8b-7f84fd7b7149",
   "metadata": {},
   "source": [
    "# Task 13: Select Features and Get Predictions\n",
    "\n",
    "Let’s select the features from the test data and get a prediction based on those features. To complete this task, do the following:\n",
    "\n",
    "1. Use CountVectorizer.transform from Task 9 to select features from the test_data.\n",
    "\n",
    "2. After getting the features from the test_data, use the predict() method from Task 11 to get the prediction using the classifier.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d0db268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 13: Select Features and Get Predictions\n",
    "\n",
    "test_data_feature = count_vectorizer.transform(test_data['text'])\n",
    "prediction = classifier.predict(test_data_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5a75077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 109)\\t3\\n  (0, 689)\\t3\\n  (0, 856)\\t3\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 689)\\t1\\n  (0, 700)\\t1\\n  (0, 909)\\t1\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 1)\\t1\\n  (0, 110)\\t1\\n  (0, 673)\\t1\\n  (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 176)\\t1\\n  (0, 689)\\t1\\n  (0, 1036)\\t1\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 1)\\t1\\n  (0, 176)\\t1\\n  (0, 214)\\t1\\n  (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0, 48)\\t1\\n  (0, 689)\\t1\\n  (0, 1933)\\t2\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0, 214)\\t1\\n  (0, 343)\\t1\\n  (0, 1865)\\t1\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0, 193)\\t2\\n  (0, 344)\\t1\\n  (0, 689)\\t1\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0, 110)\\t1\\n  (0, 211)\\t1\\n  (0, 245)\\t2\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0, 508)\\t1\\n  (0, 689)\\t1\\n  (0, 2302)\\t1\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(0, 125)\\t1\\n  (0, 373)\\t1\\n  (0, 2339)\\t1\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(0, 696)\\t1\\n  (0, 12031)\\t1\\n  (0, 49233)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(0, 109)\\t1\\n  (0, 176)\\t1\\n  (0, 689)\\t1\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(0, 1)\\t5\\n  (0, 152)\\t1\\n  (0, 214)\\t1\\n  (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(0, 28)\\t1\\n  (0, 176)\\t1\\n  (0, 343)\\t1\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(0, 214)\\t1\\n  (0, 343)\\t1\\n  (0, 672)\\t2\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(0, 214)\\t1\\n  (0, 668)\\t1\\n  (0, 686)\\t2\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(0, 28)\\t1\\n  (0, 176)\\t1\\n  (0, 689)\\t1\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(0, 109)\\t1\\n  (0, 250)\\t1\\n  (0, 669)\\t1\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(0, 1)\\t1\\n  (0, 277)\\t1\\n  (0, 319)\\t1\\n  (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0     (0, 109)\\t3\\n  (0, 689)\\t3\\n  (0, 856)\\t3\\n ...\n",
       "1     (0, 689)\\t1\\n  (0, 700)\\t1\\n  (0, 909)\\t1\\n ...\n",
       "2     (0, 1)\\t1\\n  (0, 110)\\t1\\n  (0, 673)\\t1\\n  (...\n",
       "3     (0, 176)\\t1\\n  (0, 689)\\t1\\n  (0, 1036)\\t1\\n...\n",
       "4     (0, 1)\\t1\\n  (0, 176)\\t1\\n  (0, 214)\\t1\\n  (...\n",
       "5     (0, 48)\\t1\\n  (0, 689)\\t1\\n  (0, 1933)\\t2\\n ...\n",
       "6     (0, 214)\\t1\\n  (0, 343)\\t1\\n  (0, 1865)\\t1\\n...\n",
       "7     (0, 193)\\t2\\n  (0, 344)\\t1\\n  (0, 689)\\t1\\n ...\n",
       "8     (0, 110)\\t1\\n  (0, 211)\\t1\\n  (0, 245)\\t2\\n ...\n",
       "9     (0, 508)\\t1\\n  (0, 689)\\t1\\n  (0, 2302)\\t1\\n...\n",
       "10    (0, 125)\\t1\\n  (0, 373)\\t1\\n  (0, 2339)\\t1\\n...\n",
       "11    (0, 696)\\t1\\n  (0, 12031)\\t1\\n  (0, 49233)\\t...\n",
       "12    (0, 109)\\t1\\n  (0, 176)\\t1\\n  (0, 689)\\t1\\n ...\n",
       "13    (0, 1)\\t5\\n  (0, 152)\\t1\\n  (0, 214)\\t1\\n  (...\n",
       "14    (0, 28)\\t1\\n  (0, 176)\\t1\\n  (0, 343)\\t1\\n  ...\n",
       "15    (0, 214)\\t1\\n  (0, 343)\\t1\\n  (0, 672)\\t2\\n ...\n",
       "16    (0, 214)\\t1\\n  (0, 668)\\t1\\n  (0, 686)\\t2\\n ...\n",
       "17    (0, 28)\\t1\\n  (0, 176)\\t1\\n  (0, 689)\\t1\\n  ...\n",
       "18    (0, 109)\\t1\\n  (0, 250)\\t1\\n  (0, 669)\\t1\\n ...\n",
       "19    (0, 1)\\t1\\n  (0, 277)\\t1\\n  (0, 319)\\t1\\n  (..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_data_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed259bcb-1d64-4ba6-877f-2dfaed3e691d",
   "metadata": {},
   "source": [
    "# Task 14: Evaluate the Predictions\n",
    "\n",
    "After getting the predictions from the classifier, evaluate the predictions using the following methods:\n",
    "\n",
    "1. Print all the predictions and test_labels side by side to visualize the results.\n",
    "    \n",
    "2. Use the accuracy_score() method from Task 11 to print the score of the classifier on the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "336f2cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAKE FAKE\n",
      "FAKE FAKE\n",
      "FAKE FAKE\n",
      "FAKE FAKE\n",
      "REAL REAL\n",
      "FAKE FAKE\n",
      "REAL REAL\n",
      "FAKE FAKE\n",
      "FAKE FAKE\n",
      "FAKE FAKE\n",
      "FAKE FAKE\n",
      "REAL REAL\n",
      "FAKE FAKE\n",
      "REAL REAL\n",
      "FAKE FAKE\n",
      "REAL REAL\n",
      "REAL REAL\n",
      "FAKE FAKE\n",
      "REAL REAL\n",
      "FAKE FAKE\n",
      "Accuracy:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_labels)):\n",
    "    print(test_labels[i], prediction[i])\n",
    "\n",
    "score = accuracy_score(test_labels, prediction)\n",
    "print(\"Accuracy: \", score*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac3266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
